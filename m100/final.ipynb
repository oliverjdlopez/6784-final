{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-15T05:33:17.735605643Z",
     "start_time": "2023-12-15T05:33:13.046878050Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../exadata-main/parquet_dataset/query_tool\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from query_tool import M100DataClient\n",
    "from matplotlib import pyplot as plt\n",
    "from models import *\n",
    "\n",
    "dataset_path = \"../data/m100\"\n",
    "processed_path = \"../data\"\n",
    "client = M100DataClient(dataset_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T03:20:22.544062182Z",
     "start_time": "2023-12-15T03:20:22.532550003Z"
    }
   },
   "id": "69312daeeea98570"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T03:20:23.381166205Z",
     "start_time": "2023-12-15T03:20:22.537661962Z"
    }
   },
   "id": "a3424875430753d9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "    def __init__(self, feature_dim, action_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(feature_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def train_epoch(model, trainloader, optimizer, loss_fn, scheduler=None, n_batches=-1):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    # Iterating over data to carry out training step\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        if n_batches == ii:\n",
    "            del inputs, labels\n",
    "            break\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outs = model.forward(inputs)\n",
    "        outs, labels = torch.squeeze(outs), torch.squeeze(labels)\n",
    "        loss = loss_fn(outs, labels)\n",
    "        losses.append(loss.detach().cpu())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del inputs, labels, outs\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    return losses\n",
    "\n",
    "def test_epoch(model, testloader, loss_fn, n_batches=-1):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        # Iterating over data to carry out training step\n",
    "        for ii, (inputs, labels) in enumerate(testloader):\n",
    "            if n_batches == ii:\n",
    "                del inputs, labels\n",
    "                break\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outs = model.forward(inputs)\n",
    "            outs, labels = torch.squeeze(outs), torch.squeeze(labels)\n",
    "            loss = loss_fn(outs, labels)\n",
    "            losses.append(loss)\n",
    "            del inputs, labels, outs\n",
    "\n",
    "    model.eval()\n",
    "    return losses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T04:11:52.633393210Z",
     "start_time": "2023-12-15T04:11:52.609802144Z"
    }
   },
   "id": "f220174d28672a63"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "#TODO FOR BOTH: TIMESTAMP INDICES\n",
    "\n",
    "def extract_with_nodes(feature_list, index, nodes_of_interest, columns, year_month, n_rows = None, by_indices = None):\n",
    "    node_dfs = []\n",
    "    for f in feature_list: \n",
    "        query_df = client.query(f, \n",
    "                      columns=columns,\n",
    "                      year_month=year_month)   \n",
    "        query_df.dropna(inplace=True)\n",
    "        node_list = query_df[\"node\"].to_numpy().astype(np.int32)\n",
    "        for noi in nodes_of_interest:\n",
    "            idxs = np.where(node_list == noi, True, False)\n",
    "            nodes = query_df.iloc[idxs]\n",
    "            node_values = nodes[\"value\"].values\n",
    "            \n",
    "            node_df = pd.DataFrame(index=nodes[index])\n",
    "            new_name = str(noi) + \"_\" + str(f)\n",
    "            node_df[new_name] = nodes[\"value\"].values\n",
    "            node_dfs.append(node_df)\n",
    "            \n",
    "    plugin_df=pd.concat(node_dfs, axis=1, join=\"inner\")\n",
    "    return plugin_df\n",
    "\n",
    "def extract_without_nodes(feature_list, index, columns, year_month, n_rows=None, by_indices=None):\n",
    "    dfs = []\n",
    "    for f in feature_list: \n",
    "        query_df = client.query(f, \n",
    "                      columns=columns,\n",
    "                      year_month=year_month)   \n",
    "        query_df.dropna(inplace=True)\n",
    "        df = pd.DataFrame(index=query_df[index])\n",
    "        for c in columns:\n",
    "            if c != index: #dont create column for index\n",
    "                df[f] = query_df[c].values\n",
    "        if by_indices is not None:\n",
    "            df = df[df.index.isin(by_indices)]\n",
    "        elif n_rows:\n",
    "            df = df.iloc[:n_rows]\n",
    "        df = df.loc[~df.index.duplicated(), :]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    plugin_df=pd.concat(dfs, axis=1, join=\"inner\")\n",
    "    return plugin_df\n",
    "    \n",
    "def make_df(features, columns, index, year_month, nodes_of_interest = None, n_rows = None, by_indices=None):\n",
    "    assert n_rows is not None or by_indices is not None\n",
    "    if \"node\" in columns:\n",
    "        assert nodes_of_interest != None\n",
    "        return extract_with_nodes(features, index,  nodes_of_interest, columns, year_month,n_rows = n_rows, by_indices=by_indices)\n",
    "    else:\n",
    "        return extract_without_nodes(features, index, columns, year_month, n_rows = n_rows, by_indices=by_indices)\n",
    "#ipmi collects physical/hardware properties of nodes\n",
    "def get_rack_nodes(rack_num):\n",
    "    assert rack_num < 49\n",
    "    return [i for i in range(rack_num*20, (rack_num+1)*20)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T05:05:56.539674714Z",
     "start_time": "2023-12-15T05:05:56.454901270Z"
    }
   },
   "id": "725c688ce5380726"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: int32\n",
      "Retrieving data of type: int32\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n",
      "Retrieving data of type: float\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cell purpose: pull desired features from plugins\"\"\"\n",
    "ipmi_features = [\"ambient\"]\n",
    "ipmi_columns = [\"timestamp\", \"node\", \"value\"]\n",
    "\n",
    "vertiv_features = [\"Ext_Air_Sensor_A_Temperature\", \"Ext_Air_Sensor_A_Humidity\", \"Ext_Air_Sensor_C_Temperature\", \"Ext_Air_Sensor_C_Humidity\"]\n",
    "vertiv_labels = [\"Supply_Air_Temperature\", \"Fan_Speed\"]\n",
    "vertiv_columns = [\"timestamp\", \"value\"]\n",
    "\n",
    "weather_features = [\"temp\"]\n",
    "weather_columns = [\"timestamp\", \"value\"]\n",
    "\n",
    "logics_features = [\"Tot_cdz\", \"pt\", \"pit\", \"Tot_chiller\", \"Tot_qpompe\"]\n",
    "logics_columns = [\"timestamp\", \"value\"]\n",
    "\n",
    "index = \"timestamp\"\n",
    "n_rows = 100000\n",
    "nodes_of_interest = [i*20 for i in range(49)]\n",
    "year_month = [\"22-02\"]\n",
    "\n",
    "ipmi_df=make_df(ipmi_features, ipmi_columns, index,  year_month, nodes_of_interest=nodes_of_interest, n_rows = n_rows)\n",
    "ipmi_df.to_csv(os.path.join(processed_path, \"ipmi.csv\"))\n",
    "by_indices = ipmi_df.index\n",
    "del ipmi_df\n",
    "# \n",
    "logics_df=make_df(logics_features, logics_columns,index,  year_month, by_indices = by_indices)\n",
    "logics_df.to_csv(os.path.join(processed_path, \"logics.csv\"))\n",
    "del logics_df\n",
    "\n",
    "weather_df = make_df(weather_features, weather_columns,index,   year_month, by_indices=by_indices)\n",
    "weather_df.to_csv(os.path.join(processed_path, \"weather.csv\"))\n",
    "del weather_df\n",
    "vertiv_df = make_df(vertiv_features, vertiv_columns, index,year_month, nodes_of_interest=nodes_of_interest, by_indices=by_indices)\n",
    "vertiv_df.to_csv(os.path.join(processed_path, \"vertiv.csv\"))\n",
    "del vertiv_df\n",
    "vertiv_labels = make_df(vertiv_labels, vertiv_columns, index,  year_month, nodes_of_interest=nodes_of_interest, by_indices=by_indices)\n",
    "vertiv_labels.to_csv(os.path.join(processed_path, \"vertiv_labels.csv\"))\n",
    "del vertiv_labels\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T05:06:21.680612965Z",
     "start_time": "2023-12-15T05:05:58.414003778Z"
    }
   },
   "id": "22578a71535bd1bf"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     0_ambient  20_ambient  40_ambient  60_ambient  80_ambient  100_ambient  \\\n0         21.8        20.6        22.6        23.6        24.0         23.6   \n1         21.8        20.6        22.4        23.6        24.0         23.6   \n2         21.8        20.8        22.4        23.4        23.8         23.6   \n3         21.6        21.0        22.4        23.4        23.8         23.4   \n4         21.6        21.0        22.4        23.2        23.6         23.4   \n..         ...         ...         ...         ...         ...          ...   \n838       21.6        18.8        21.2        22.2        23.0         23.2   \n839       21.4        18.8        21.2        22.2        23.0         23.2   \n840       21.4        18.8        21.2        22.2        23.0         23.2   \n841       21.2        18.8        21.2        22.2        22.8         23.2   \n842       21.0        18.8        21.2        22.2        22.8         23.0   \n\n     120_ambient  140_ambient  160_ambient  180_ambient  ...  \\\n0           24.8         25.4         24.6         24.8  ...   \n1           24.8         25.4         24.6         24.8  ...   \n2           24.8         25.4         24.6         24.8  ...   \n3           24.6         25.2         24.6         24.8  ...   \n4           24.6         25.2         24.6         24.8  ...   \n..           ...          ...          ...          ...  ...   \n838         25.0         25.6         24.2         24.6  ...   \n839         25.0         25.6         24.2         24.6  ...   \n840         25.0         25.6         24.2         24.6  ...   \n841         25.0         25.6         24.2         24.6  ...   \n842         25.0         25.6         24.2         24.6  ...   \n\n     Ext_Air_Sensor_A_Humidity  Ext_Air_Sensor_C_Temperature  \\\n0                         27.8                           7.5   \n1                         28.4                           8.5   \n2                         27.6                           8.3   \n3                         31.8                          10.0   \n4                         28.2                           8.6   \n..                         ...                           ...   \n838                       11.0                           4.9   \n839                       11.0                           4.9   \n840                       10.9                           4.9   \n841                       10.9                           4.9   \n842                       11.0                           4.9   \n\n     Ext_Air_Sensor_C_Humidity  Tot_cdz      pt     pit  Tot_chiller  \\\n0                         68.1     20.6  376184  247160        169.3   \n1                         63.5     15.4  372221  245840        171.5   \n2                         63.2     15.6  373350  247200        117.1   \n3                         66.5     15.7  359431  245760        170.0   \n4                         65.1     15.9  376573  246360        169.6   \n..                         ...      ...     ...     ...          ...   \n838                       34.2     27.2  363412  245480        111.6   \n839                       34.2     17.3  336417  246280        170.8   \n840                       34.1     27.5  363279  246080        116.4   \n841                       34.1     22.4  378839  245400        116.3   \n842                       34.1     27.7  348361  247160        116.6   \n\n     Tot_qpompe  Supply_Air_Temperature  Fan_Speed  \n0          20.8                    21.1       60.0  \n1          21.1                    19.9       60.0  \n2          20.9                    19.5       60.0  \n3          20.9                    22.7       60.0  \n4          21.1                    20.5       60.0  \n..          ...                     ...        ...  \n838        21.0                    24.4       60.0  \n839        20.9                    24.4       60.0  \n840        20.7                    24.4       60.0  \n841        20.8                    24.4       60.0  \n842        20.8                    24.4       60.0  \n\n[843 rows x 61 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_ambient</th>\n      <th>20_ambient</th>\n      <th>40_ambient</th>\n      <th>60_ambient</th>\n      <th>80_ambient</th>\n      <th>100_ambient</th>\n      <th>120_ambient</th>\n      <th>140_ambient</th>\n      <th>160_ambient</th>\n      <th>180_ambient</th>\n      <th>...</th>\n      <th>Ext_Air_Sensor_A_Humidity</th>\n      <th>Ext_Air_Sensor_C_Temperature</th>\n      <th>Ext_Air_Sensor_C_Humidity</th>\n      <th>Tot_cdz</th>\n      <th>pt</th>\n      <th>pit</th>\n      <th>Tot_chiller</th>\n      <th>Tot_qpompe</th>\n      <th>Supply_Air_Temperature</th>\n      <th>Fan_Speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.8</td>\n      <td>20.6</td>\n      <td>22.6</td>\n      <td>23.6</td>\n      <td>24.0</td>\n      <td>23.6</td>\n      <td>24.8</td>\n      <td>25.4</td>\n      <td>24.6</td>\n      <td>24.8</td>\n      <td>...</td>\n      <td>27.8</td>\n      <td>7.5</td>\n      <td>68.1</td>\n      <td>20.6</td>\n      <td>376184</td>\n      <td>247160</td>\n      <td>169.3</td>\n      <td>20.8</td>\n      <td>21.1</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.8</td>\n      <td>20.6</td>\n      <td>22.4</td>\n      <td>23.6</td>\n      <td>24.0</td>\n      <td>23.6</td>\n      <td>24.8</td>\n      <td>25.4</td>\n      <td>24.6</td>\n      <td>24.8</td>\n      <td>...</td>\n      <td>28.4</td>\n      <td>8.5</td>\n      <td>63.5</td>\n      <td>15.4</td>\n      <td>372221</td>\n      <td>245840</td>\n      <td>171.5</td>\n      <td>21.1</td>\n      <td>19.9</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.8</td>\n      <td>20.8</td>\n      <td>22.4</td>\n      <td>23.4</td>\n      <td>23.8</td>\n      <td>23.6</td>\n      <td>24.8</td>\n      <td>25.4</td>\n      <td>24.6</td>\n      <td>24.8</td>\n      <td>...</td>\n      <td>27.6</td>\n      <td>8.3</td>\n      <td>63.2</td>\n      <td>15.6</td>\n      <td>373350</td>\n      <td>247200</td>\n      <td>117.1</td>\n      <td>20.9</td>\n      <td>19.5</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21.6</td>\n      <td>21.0</td>\n      <td>22.4</td>\n      <td>23.4</td>\n      <td>23.8</td>\n      <td>23.4</td>\n      <td>24.6</td>\n      <td>25.2</td>\n      <td>24.6</td>\n      <td>24.8</td>\n      <td>...</td>\n      <td>31.8</td>\n      <td>10.0</td>\n      <td>66.5</td>\n      <td>15.7</td>\n      <td>359431</td>\n      <td>245760</td>\n      <td>170.0</td>\n      <td>20.9</td>\n      <td>22.7</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21.6</td>\n      <td>21.0</td>\n      <td>22.4</td>\n      <td>23.2</td>\n      <td>23.6</td>\n      <td>23.4</td>\n      <td>24.6</td>\n      <td>25.2</td>\n      <td>24.6</td>\n      <td>24.8</td>\n      <td>...</td>\n      <td>28.2</td>\n      <td>8.6</td>\n      <td>65.1</td>\n      <td>15.9</td>\n      <td>376573</td>\n      <td>246360</td>\n      <td>169.6</td>\n      <td>21.1</td>\n      <td>20.5</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>21.6</td>\n      <td>18.8</td>\n      <td>21.2</td>\n      <td>22.2</td>\n      <td>23.0</td>\n      <td>23.2</td>\n      <td>25.0</td>\n      <td>25.6</td>\n      <td>24.2</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>4.9</td>\n      <td>34.2</td>\n      <td>27.2</td>\n      <td>363412</td>\n      <td>245480</td>\n      <td>111.6</td>\n      <td>21.0</td>\n      <td>24.4</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>21.4</td>\n      <td>18.8</td>\n      <td>21.2</td>\n      <td>22.2</td>\n      <td>23.0</td>\n      <td>23.2</td>\n      <td>25.0</td>\n      <td>25.6</td>\n      <td>24.2</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>4.9</td>\n      <td>34.2</td>\n      <td>17.3</td>\n      <td>336417</td>\n      <td>246280</td>\n      <td>170.8</td>\n      <td>20.9</td>\n      <td>24.4</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>21.4</td>\n      <td>18.8</td>\n      <td>21.2</td>\n      <td>22.2</td>\n      <td>23.0</td>\n      <td>23.2</td>\n      <td>25.0</td>\n      <td>25.6</td>\n      <td>24.2</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>10.9</td>\n      <td>4.9</td>\n      <td>34.1</td>\n      <td>27.5</td>\n      <td>363279</td>\n      <td>246080</td>\n      <td>116.4</td>\n      <td>20.7</td>\n      <td>24.4</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>21.2</td>\n      <td>18.8</td>\n      <td>21.2</td>\n      <td>22.2</td>\n      <td>22.8</td>\n      <td>23.2</td>\n      <td>25.0</td>\n      <td>25.6</td>\n      <td>24.2</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>10.9</td>\n      <td>4.9</td>\n      <td>34.1</td>\n      <td>22.4</td>\n      <td>378839</td>\n      <td>245400</td>\n      <td>116.3</td>\n      <td>20.8</td>\n      <td>24.4</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>21.0</td>\n      <td>18.8</td>\n      <td>21.2</td>\n      <td>22.2</td>\n      <td>22.8</td>\n      <td>23.0</td>\n      <td>25.0</td>\n      <td>25.6</td>\n      <td>24.2</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>4.9</td>\n      <td>34.1</td>\n      <td>27.7</td>\n      <td>348361</td>\n      <td>247160</td>\n      <td>116.6</td>\n      <td>20.8</td>\n      <td>24.4</td>\n      <td>60.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>843 rows Ã— 61 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv(os.path.join(processed_path, \"weather.csv\"))\n",
    "vertiv_df = pd.read_csv(os.path.join(processed_path, \"vertiv.csv\"))\n",
    "vertiv_labels = pd.read_csv(os.path.join(processed_path, \"vertiv_labels.csv\"))\n",
    "ipmi_df = pd.read_csv(os.path.join(processed_path, \"ipmi.csv\"))\n",
    "logics_df = pd.read_csv(os.path.join(processed_path, \"logics.csv\"))\n",
    "\n",
    "weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.round(\"min\")\n",
    "vertiv_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.round(\"min\")\n",
    "vertiv_labels [\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.round(\"min\")\n",
    "ipmi_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.round(\"min\")\n",
    "logics_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.round(\"min\")\n",
    "\n",
    "plugin_dfs = [ipmi_df, weather_df, vertiv_df, logics_df, vertiv_labels]\n",
    "\n",
    "df = plugin_dfs[0].drop(\"timestamp\", axis=1)\n",
    "for d in plugin_dfs[1:]:\n",
    "    df = df.merge(d.drop(\"timestamp\", axis=1), left_index=True, right_index=True)\n",
    "df\n",
    "\n",
    "#notes: we lose a lot of measurements because timestamps do not overlap. We might want to define an acceptabel margin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T05:33:59.330744271Z",
     "start_time": "2023-12-15T05:33:58.476807581Z"
    }
   },
   "id": "176c98e2cc36cbe1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.index[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.090673782Z"
    }
   },
   "id": "36e179ab1ac4ab65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Cell purpose: preprocess and/or merge data as desired\"\"\"\n",
    "# \n",
    "# feature_list = itertools.chain(ipmi_features, weather_features, vertiv_features)\n",
    "# label_list = itertools.chain(vertiv_labels) \n",
    "feature_list = [\"0_ambient\", \"9_ambient\", \"temp\", \"Supply_Air_Temperature\"]\n",
    "label_list = [\"Return_Air_Temperature\"]\n",
    "\n",
    "train_df, test_df = train_test_split(df)\n",
    "train_df, test_df = train_df.iloc[:-1], test_df.iloc[1:] #align t and t+1\n",
    "train_features, test_features = train_df[feature_list], test_df[feature_list]\n",
    "train_labels, test_labels = train_df[label_list], test_df[label_list]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139004256Z"
    }
   },
   "id": "6b1733a0c94ce8c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Will have to make work with timestamp indexign later\n",
    "class M100Data(Dataset):\n",
    "    def __init__(self, feature_df, label_df, transform = None, label_transform = None):\n",
    "        self.feature_df = feature_df\n",
    "        self.label_df = label_df\n",
    "        self.feature_dim = self.feature_df.shape[1]\n",
    "        self.label_dim = self.label_df.shape[1]\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.feature_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = torch.as_tensor(self.feature_df.iloc[idx].values, dtype=torch.float32)\n",
    "        label = torch.as_tensor(self.label_df.iloc[idx].values, dtype=torch.float32)\n",
    "        return feature, label\n",
    "    \n",
    "train_ds = M100Data(train_features, train_labels)\n",
    "trainloader = DataLoader(train_ds, batch_size = 8, shuffle = True)\n",
    "\n",
    "test_ds = M100Data(test_features, test_labels)\n",
    "testloader = DataLoader(test_ds, batch_size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139293404Z"
    }
   },
   "id": "4a17ace650982f45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model = LinearNN(train_ds.feature_dim, train_ds.label_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), 1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for _ in range(epochs):\n",
    "    train_losses.append(train_epoch(model, trainloader, optimizer, loss_fn))\n",
    "    test_losses.append(test_epoch(model, testloader, loss_fn))\n",
    "train_losses = np.array(train_losses)\n",
    "test_losses = np.array(test_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T03:20:24.141364804Z",
     "start_time": "2023-12-15T03:20:24.139515804Z"
    }
   },
   "id": "96a5aadcd8397788"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses.shape\n",
    "test_losses.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139634601Z"
    }
   },
   "id": "da89ca240a6e4c2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_avg_epoch_loss(train_losses, test_losses):\n",
    "    assert len(train_losses) == len(test_losses) #num of epochs should be the same\n",
    "    avg_train_losses = np.mean(train_losses, axis=1)\n",
    "    avg_test_losses = np.mean(test_losses, axis=1)\n",
    "    timesteps = [t for t in range(len(avg_train_losses))]\n",
    "    # colors = iter(plt.cm.viridis(np.linspace(0, 0.5, 2)))\n",
    "    plt.plot(timesteps, avg_train_losses, c=\"blue\", label=\"Training loss\")\n",
    "    plt.plot(timesteps, avg_test_losses, c=\"red\", label=\"Testing loss\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139727302Z"
    }
   },
   "id": "118a70fbe9449cf1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Cell purpose: benchmarking\"\"\"\n",
    "plot_avg_epoch_loss(train_losses, test_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139807018Z"
    }
   },
   "id": "46493ce89db187d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139873485Z"
    }
   },
   "id": "8ca995608b0b8e6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-15T03:20:24.139936672Z"
    }
   },
   "id": "80fd1620c5c3f872"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
